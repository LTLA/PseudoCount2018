\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in,marginparwidth=2in]{geometry}

% use Unicode characters - try changing the option if you run into troubles with special characters (e.g. umlauts)
\usepackage[utf8]{inputenc}

% clean citations
\usepackage{cite}

% hyperref makes references clicky. use \url{www.example.com} or \href{www.example.com}{description} to add a clicky url
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% improves typesetting in LaTeX
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% text layout - change as needed
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Remove % for double line spacing
%\usepackage{setspace} 
%\doublespacing

% use adjustwidth environment to exceed text width (see examples in text)
\usepackage{changepage}

% adjust caption style
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,singlelinecheck=off]{caption}

% remove brackets from references
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% headrule, footrule and page numbers
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}

% use \textcolor{color}{text} for colored text (e.g. highlight to-do areas)
\usepackage{color}

% define custom colors (this one is for figure captions)
\definecolor{Gray}{gray}{.25}

% this is required to include graphics
\usepackage{graphicx}

% use if you want to put caption to the side of the figure - see example in text
\usepackage{sidecap}

% use for have text wrap around figures
\usepackage{wrapfig}
\usepackage[pscoord]{eso-pic}
\usepackage[fulladjust]{marginnote}
\reversemarginpar

% Adding multirow.
\usepackage{multirow}

% Other required things:
\usepackage{color}
\usepackage{subcaption}
\captionsetup[subfigure]{justification=centering}
\usepackage{amsmath}
\newcommand\code[1]{{\small\texttt{#1}}}

% document begins here
\begin{document}
\vspace*{0.35in}

% title goes here:
\begin{flushleft}
{\Large
    \textbf\newline{Using an appropriate pseudo-count for log-transformation of normalized single-cell RNA sequencing data}
}
\newline

% authors go here:
%\\
Aaron Lun\textsuperscript{1,*}
\\
\bigskip
\bf{1} Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\
\bigskip

\end{flushleft}

\section{Background}
Log-transformed expression values are widely used in analyses of single-cell RNA sequencing (scRNA-seq) and other transcriptomic data.
This is driven by the simplicity of the log-transformation and its variance stabilizing behaviour on many types of non-negative data.
In particular, the log-transformation reduces the impact of stochastic fluctuations in the counts for high-abundance genes.
This would otherwise result in large differences in the counts that are mostly uninteresting as the fold changes are small.
Differences between log-values are also approximately interpretable as log-fold changes between cells, which are often more relevant than differences in the counts.
This is useful for ensuring that the relative rather than absolute differences in the counts are used in distance-based procedures like clustering or trajectory construction.

Despite its popularity, the log-transformation has a number of problems such as incomplete variance stabilization and arbitrariness in the choice of pseudo-count.
One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count \cite{hicks2017missing}.
This is problematic in (sc)RNA-seq contexts where the log-transformation is applied to normalized expression data.
Here, normalization is performed to remove inter-sample biases on the count scale \cite{robinson2010scaling,lun2016pooling}.
For genes that are not differentially expressed (DE), the expectation of the normalized expression is the same between samples.
However, the expectation of the log-normalized values may not be the same, resulting in spurious differences between samples/cells on the log-scale.

In this report, we describe the nature and impact of the discrepancy between log-mean and mean-log values.
We also show how the added pseudo-count can be increased to cap the discrepancy at the cost of reducing interpretability.

\section{Quantifying the discrepancy}
Let $X_{ig}$ denote a random variable for a non-negative count of a gene $g$ in cell $i$.
The size factor $s_i$ represents the scaling bias in $i$, which is removed by computing the normalized expression value $X_{ig}/s_i$.
The log-transformed normalized expression is defined as 
\[
Z_{ig} = \log\left(\frac{X_{ig}}{s_i}+ c\right) \;,
\]
where $c$ is a pseudo-count that ensures that the transformation is defined for $X_{ig} \ge 0$.
The second-order Taylor series approximation for the expectation of $Z_{ig}$ is
\[
E(Z_{ig}) \approx \log[E(X_{ig}/s_i) + c] - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2[E(X_{ig}/s_i) + c]^2} \;.
\]
The second term represents the discrepancy between the mean-log and the log-mean.

Now, consider two cells $i=1$ and $i=2$ that differ in their $s_i$.
Assume that $g$ is non-DE between these two cells such that $E(X_{ig}/s_i)=\mu_g$ for both.
The true log-fold change in the normalized expression values between these two cells is
\[
\delta_{12g} = \log\left[ \frac{E(X_{1g}/s_1)}{E(X_{2g}/s_2)} \right] = 0 \;.
\]
In analyses based on the log-transformed values, we use the difference in $E(Z_{ig})$ as a proxy for $\delta_{12g}$.
First, we simplify the expression for $E(Z_i)$ to
\[
E(Z_{ig}) \approx \log(\mu_g + c) - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2(\mu_g + c)^2} \;.
\]
This means that the difference in $E(Z_{ig})$ between these two cells is 
\begin{equation}
\Delta_{12g} \approx \frac{\mbox{var}(X_{1g})s_1^{-2} -  \mbox{var}(X_{2g})s_2^{-2}}{2(\mu_g + c)^2} \;. \label{eqn:spuriousdiff}
\end{equation}
In general, $\Delta_{12g} \neq 0$ due to differences in the size factors and subsequently variances (driven by the strong mean-variance relationship in count data).
This represents a spurious difference on the log-scale as the gene is not actually DE, i.e., $\delta_{12g}=0$.

We performed simulations to quantify this spurious difference in a range of scenarios for the typical $c=1$ (Figure~\ref{fig:maxeffect}).
We observed that it was most prominent when the size factors were different and either or both of them were less than unity.
This is consistent with Equation~\ref{eqn:spuriousdiff}, where $\Delta_{12g}$ increases in magnitude with smaller $s_i$.
We note that a 10-fold difference in the size factors across cells is not unusual in real scRNA-seq data \cite{lun2016pooling} due to the variability of capture efficiency and amplification.
However, even in this situation, we can obtain a difference of 1 in the mean log-values.
This corresponds to an artificial 2-fold change in expression that does not correspond to any biological effect.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the mean log$_2$-expression values for a non-DE gene due to size factor differences.
We simulated counts for non-DE genes in two groups of cells, where the size factor was the same for all cells in the same group (see Methods).
Each simulation scenario was defined by the size factor used for the first group ($a_1$), that for the second group ($a_2$), and the negative binomial dispersion.
For each scenario, we computed the difference between the mean $Z_{ig}$ for each group and determined the maximum difference across genes of varying abundance.
Values represent the average of the maximum across 10 simulation iterations.
Standard errors were negligible and are not shown.
For simplicity, we only show results for scenarios where $a_1 \ge a_2$.
}
\label{fig:maxeffect}
\end{figure}

We verified the existence of this effect in real scRNA-seq data from the 10X Genomics platform \cite{zheng2017massively}.
We used the publicly available ERCC data set (see Methods) in which gel emulsion beads containing ERCC spike-in transcripts were captured into droplets.
The composition of the ERCC transcripts should be constant in all droplets, so there should not be any difference in the expression profiles after library size normalization.
However, we observed a systematic non-zero difference in the mean log-expression values when comparing the smallest and largest droplets (Figure~\ref{fig:ercc}a).
This is fully attributable to the log-transformation, as no such difference is present in the log-fold change between the mean normalized expression values (Figure~\ref{fig:ercc}b).

\begin{figure}
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\caption{Effect of log-transformation on the comparison between large and small droplets in the ERCC 10X Genomics data set.
(a) Differences in the mean $Z_{ig}$ between the top 20\% of libraries with the largest size factors and the bottom 20\% (see Methods).
Each point represents a single ERCC spike-in transcript.
(b) Log-fold change in the mean normalized count between the same groups of libraries for each ERCC transcript.}
\label{fig:ercc}
\end{figure}

The effect of spurious differences in $E(Z_{ig})$ is amplified in procedures that compute distances between cells.
Consider the Euclidean distance between the expected log-normalized expression profiles of our two cells $i=1$ and 2.
Ideally, the distance would be zero as there should be no difference in the expected location of these cells after normalization.
However, the actual distance will be approximately equal to the square root of the sum of $\Delta_{12g}^2$ across all (non-DE) genes used in the calculation.
This means that the distance between cells with different $s_i$ will be systematically larger than between cells with the same $s_i$.
As a result, spurious clusters or trajectories can form (Figure~\ref{fig:structures}) solely due to the log-transformation.
Such artificial structures can be highly misleading when characterizing the heterogeneity of a cellular population.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/clusters.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/trajectory.pdf}
    \caption{}
\end{subfigure}
\caption{Artificial structures induced by log-transformation in simulations with no true structure.
(a) Principal components analysis (PCA) plot of log-normalized expression values for non-DE genes in simulated cells with either very small or very large size factors (see Methods).
Each point represents a cell coloured according to its value of $s_i$.
The percentage of variance explained by each principal component (PC) is also shown in parentheses. 
(b) PCA plot for simulated cells with $s_i$ sampled from a continuous distribution.
Each point represents a cell coloured by its value of $s_i$.
}
\label{fig:structures}
\end{figure}

\section{Exploring possible remedies}
The obvious solution is to use methods that model the counts directly to account for the mean-variance relationship.
For example, we could use \textit{BASiCS} \cite{vallejos2016beyond} for detecting highly variable genes or \textit{zinbwave} \cite{risso2018general} for factor analysis.
This avoids the need for any variance-stabilizing transformation and subsequent distortion of the expected expression.
However, most existing methods for scRNA-seq data analysis (e.g., clustering, dimensionality reduction) do not use count-based models.
This is due to the difficulties in estimating model parameters, often separately for each gene and/or each cell,
compared to algorithms that only need distances between cells as input.
Thus, it is still desirable to obtain transformed data for compatibility with existing analysis methods.

Another possible solution is to remove discrepancies empirically after transformation.
This is done in various types of batch correction \cite{ritchie2015limma,haghverdi2018batch} where systematic differences in transformed values between batches are eliminated.
It is, however, not straightforward to achieve in general as the magnitude of the discrepancy depends on the mean (Equation~\ref{eqn:spuriousdiff}).
An empirical correction would require an approach similar to that used in \textit{SCnorm} \cite{bacher2017scnorm}.
If we assume that most genes at any given abundance interval are mostly non-DE across all cells, any systematic trends in the transformed values with respect to $s_i$ for the genes in that interval must be artificial and should be removed.
This assumption is considerably stronger than that used in scaling normalization (which only requires a non-DE majority across all genes),
and cannot handle enrichment of DE genes, e.g., at high abundances due to strong upregulation.
It is also difficult to fit an accurate and robust trend to discrete transformed values for low-abundance genes.

A more drastic approach would be to downsample all cells to match the cell with the smallest size factor.
This would ensure that the variance (for Poisson-distributed counts) is the same across all cells, thus avoiding spurious log-fold changes between cells.
However, it involves discarding a large amount of sequencing information and is equivalent to forcibly increasing the noise for high-quality cells that were deeply sequenced.
Biological signal may subsequently be lost, especially if the size factors are highly variable and considerable downsampling is required.
Downsampling also assumes that the counts are Poisson-distributed.
This may be true for the sequencing itself \cite{marioni2008rnaseq} but is not true in general for library preparation.
Overdispersion (e.g., due to PCR amplification) would mean that the downsampled counts of cells with large size factors will still have smaller variance than the counts of cells with small size factors.

Finally, we explore the use of other transformations with different statistical properties.
We considered the square root, which provides good variance stabilization for Poisson-distributed counts;
and the variance stabilizing transformation (VST) for negative binomial (NB)-distributed counts from \emph{DESeq2} \cite{love2014moderated}.
In simulations of non-DE genes, we observed large differences in the mean of transformed values with both transformations (Figure~\ref{fig:alttransform}).
This indicates that variance stabilization does not protect against spurious differences in the mean.
Perhaps no single transformation exists that 
(i) yields transformed values that are easily interpretable,
(ii) provides complete variance stabilization, and
(iii) avoids spurious differences in the mean of transformed values.

\begin{figure}
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\caption{Distribution of mean expression values for Poisson-distributed counts (a, b, c) or NB-distributed counts (d, e, f) after applying a variety of transformations.
Simulated count data was generated for 10000 genes in 500 cells, with the mean count set to 1 for half of the cells (smaller group) and 100 for the other half (larger group).
The dispersion was set to 1 for the NB simulations.
Size factors were calculated by scaling the library sizes to a mean of unity across cells.
Transformations were applied to the size factor-scaled counts, using a pseudo-count of 1 for the log$_2$-transformation and \code{fitType="mean"} for the \textit{DESeq2} VST.
Boxplots represent the distribution of mean transformed values across genes, with outlier genes shown as separate dots.
}
\label{fig:alttransform}
\end{figure}

\section{Validating structure with DE analyses}
In our opinion, the most effect of greatest concern is the formation of spurious clusters and trajectories.
This can easily result in incorrect biological conclusions from an exploratory analysis of scRNA-seq data.
That said, careful further analysis can provide some protection against these artificial structures.
Say that we identify spurious clusters like those in Figure~\ref{fig:structures}.
We attempt to characterize these clusters by identifying genes that are differentially expressed between them.
Here, the key is to use count-based models like edgeR \cite{robinson2010edgeR} to perform the DE analysis.
This avoids spurious non-zero differences in expression due to the log-transformation.
If the analysis fails to yield any DE genes, we can infer that the separation was driven by the log-transformation and should be ignored.
In this manner, we can avoid drawing misleading conclusions.

While count-based models provide some protection from spurious structure, it is often the case that we still need to use per-gene transformed values for other steps in the analysis.
This includes visualization of expression between groups (e.g., in boxplots, or by colouring dimensionality reduction plots), for which the log-transformation is often used to preserve relative differences across a wide range of expression values.
It may also be more convenient to perform DE analyses on the log-transformed values, e.g., using $t$-tests \cite{law2014voom}, which are much faster and simpler than count-based models.
Thus, we would like to reduce $\Delta_{12g}$ as much as possible for these applications.
The most obvious method of doing so is to increase the pseudo-count.
Indeed, we could force $\Delta_{12g}$ to zero for all genes by setting $c$ to some arbitrarily large value.
However, as $c \to \infty$, the log-transformation approaches a linear transformation, i.e.,
\[
    Z_{ig} \approx \log(c) + \frac{X_{ig}}{s_i c} \;.
\]
Thus, using an arbitrarily large pseudo-count defeats the intended purpose of the log-transformation. 
No variance stabilization is achieved and differences in the transformed values cannot be used as proxies for log-fold changes. 
Instead, we aim to choose a pseudo-count that restricts $\Delta_{12g}$ to an ``acceptable'' level for each gene.

\section{Choosing a larger pseudo-count}

We assume that $X_{ig}$ follows a negative binomial (NB) distribution with mean $s_i\mu_g$ and dispersion $\varphi$.
This means that we can simplify the expression for $\Delta_{12g}$ to
\begin{align*}
\Delta_{12} 
&\approx \frac{\mu_g s_1^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} - \frac{\mu_g s_2^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} \\ 
&= \frac{\mu_g (s_1^{-1} - s_2^{-1})}{2(\mu_g + c)^2} \;.
\end{align*}
This spurious difference in the log-expression values is maximized when $\mu_g = c$, yielding 
\[
\tilde\Delta_{12g} = \frac{(s_1^{-1} - s_2^{-1})}{8c} \;.
\]
Thus, we can cap the maximum error $\tilde\Delta_{12g}$ regardless of the values of $s_i$ by requiring 
\[
    c \propto |s_1^{-1} - s_2^{-1}| \;.
\]
If we set the proportionality constant $\rho$ to unity, the maximum log-difference should be 0.125 (or $[8\log(2)]^{-1} \approx 0.18$, on the $\log_2$-scale).
We observe this bound in a range of simulation scenarios (Figure~\ref{fig:cappederr}), indicating that our approximation is accurate.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the log-expression values for non-DE simulated data after setting $c$ to $|s_1^{-1} - s_2^{-1}|$.
Each difference was computed between the average $Z_{ig}$ of 10000 counts for $i=1$ and 2.
Counts were sampled from a negative binomial distribution with mean $\mu_g s_i$ and the specified dispersion $\varphi$.
For each combination of the first size factor ($s_1$), second size factor ($s_2$) and $\varphi$, the maximum difference was determined across all $\mu_g \in [10^{-3}, 10^3]$.
Results are not shown for scenarios where $s_1=s_2$ as no difference in log-expression is expected (dashed lines connect adjacent points for ease of visualization).
}
\label{fig:cappederr}
\end{figure}

In practice, downstream procedures such as clustering will compare many cells to one another instead of just two specific (groups of) cells.
The exact choices of $s_1$ and $s_2$ are not obvious when considering the calculation of a single pseudo-count for the entire data set.
A general strategy is to set $s_1$ to the smallest size factor and $s_2$ to the largest size factor
(or robust equivalents thereof, e.g., the 5\textsuperscript{th} and 95\textsuperscript{th} percentiles).
This ensures that the difference in log-values for a non-DE gene does not exceed the theoretical upper bound for any pair of cells.
We thus define our empirical pseudo-count as
\[
\hat c = \max\{1, \rho |s_{min}^{-1} - s_{max}^{-1}|\} \;,
\]
which ensures that the pseudo-count is at least unity when all size factors are equal.
We suggest setting $\rho=1$, which provides a compromise between restricting $\tilde\Delta_{12g}$ and keeping the pseudo-count as small as possible.
Applying this strategy to the ERCC data set limits the maximum error close to the theoretical upper bound (Figure~\ref{fig:bigreal}a).

\begin{figure}
\begin{center}
    \includegraphics[width=0.5\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/ercc.pdf}
\end{center}
\caption{Effect of log-transformation with $\hat c$ and $\rho =1$ in the ERCC data set.
Differences in the mean $Z_{ig}$ are shown between the top and bottom 20\% of libraries with the largest and smallest size factors.
The red line denotes the theoretical limit on $\tilde \Delta_{12g}$.}
\label{fig:bigreal}
\end{figure}

To explore the behaviour of $\hat c$ in real data, we computed $\hat c$ for a number of real scRNA-seq data sets from the \href{http://bioconductor.org/packages/devel/workflows/html/simpleSingleCell.html}{\emph{simpleSingleCell}} workflows.
Here, low-quality cells were removed with the \emph{scater} package \cite{mccarthy2017scater} and size factors were computed using the deconvolution method \cite{lun2016pooling}.
With $\rho=1$, we obtained $\hat c$ values of 1.36 for the 416B data set \cite{lun2017assessing}, 4.05 for the mouse brain data set \cite{zeisel2015brain} and 2.22 for the peripheral bone mononuclear cell (PBMC) data set \cite{zheng2017massively}.
These values are typical of pseudo-counts used for exploratory analyses of RNA-seq data \cite{chen2016reads}.
They are also lower than the largest average counts per gene for each data set (PBMC: 216, brain: 1664, 416B: 63215),
indicating that our recommended value for the pseudo-count is not so large as to entirely negate the variance stabilization activity of the log-transformation.     

\section{Practical use of larger pseudo-counts}
Pseudo-counts are often set to unity, which is motivated by a number of factors that have little to do with avoiding spurious differences.
One reason is to ensure that zero counts always yield zero log-values, which ensures that sparse matrix representations are still effective for reducing memory usage of large data sets.
A related motivation is to ensure that the log-transformed values are always non-negative, which is necessary for procedures such as non-negative factor analysis.
However, there is no need to conflate these considerations with the choice of pseudo-count.
Some arithmetic yields 
\[
 \log\left(\frac{X_{ig}}{s_i}+ c\right) = \log\left(\frac{X_{ig}}{cs_i}+ 1\right) + \log c \;,
\]
where the constant $\log c$ on the right hand side can be ignored in any step that involves computing differences between log-values.
Thus, instead of naively adding a non-unity $c$, we can achieve the same result by multiplying $s_i$ by the chosen $c$, performing scaling normalization with $cs_i$, and then log-transforming after adding 1 to the normalized values.
This preserves sparsity and non-negativeness in the log-expression matrix.

As an aside, it is also worth commenting on the widespread use of log-transformed counts-per-million (CPM) values and their relatives, e.g., transcripts-per-million or fragments-per-kilobase-million.
Log-CPM values are typically computed by adding 1 to the CPM values, for the same reasons mentioned above.
However, this is equivalent to using a pseudo-count equal to the library size (i.e., total count across all genes) in millions.
Data sets with an average library size of 10 million would use a pseudo-count of 10, while data sets with an average library size of 10,000 would use a pseudo-count of 0.01.
This is not desirable as data sets with small library sizes are those with the largest $\Delta_{12g}$ (as $\mu_g$ is small) and in most need of large pseudo-counts.
By comparison, the approximation of the log-fold change by differences in log-values should improve in quality with greater coverage.
Adaptively increasing the pseudo-count scales up the bias with the coverage, such that the log-fold change estimates are not consistent.

\section{Discussion}
It is worth speculating on some real situations in which the log-transformation is most likely to cause distortions.
Artifacts are most pronounced when the counts are low and there is large variation in the size factors across cells.
Both of these are often observed in data from droplet-based scRNA-seq protocols, as sequencing coverage is shared across a large number of libraries and reaction conditions are not precisely controlled for each droplet.
We would also expect the size factors within each experiment to vary across a continuum, yielding artificial trajectories (Figure~\ref{fig:structures}b) rather than distinct clusters (Figure~\ref{fig:structures}a).
This suggests that caution is required when interpreting trajectories that are correlated with the size factors, especially in low-coverage droplet-based data.

In the context of scRNA-seq analysis workflows, additional procedures can be used to reduce transformation-induced artifacts.
For example, quality control is typically performed to remove cells with small library sizes \cite{ilicic2016classification,lun2016stepbystep}.
This reduces the variation in the size factors and the potential for artificial differences upon log-transformation.
In addition, low-abundance genes can be filtered out, which provides further protection as genes with low counts are most affected by the log-transformation.
We note that the use of a larger pseudo-count will also reduce the influence of low-abundance genes.
This is a more nuanced approach than filtering, as it ensures that strong biological signal in low-abundance genes is not completely discarded for downstream applications.

Data transformations are powerful tools for exploratory analyses of scRNA-seq data.
However, they also have the potential to introduce artificial differences, as we have shown for the log-transformation.
Our recommendation is to increase the pseudo-count in cases where size factor variation may be responsible for spurious structure in the data.

\section{Methods}

\subsection{Simulated log-fold changes for non-DE genes}
We considered two groups of 10,000 cells where all cells in the same group $j$ were assigned the same size factor $s_i=a_j$.
For a non-DE gene $g$, the count $X_{ig}$ for each cell $i$ was independently sampled from a negative binomial distribution with mean $s_i\mu_g$ and dispersion $\varphi$.
We computed $Z_{ig}$ for all cells in each group using a pseudo-count $c$ of 1 as previously described.
The difference in the mean $Z_{ig}$ between groups represents an estimate of $\Delta_{12g}$.
The maximum difference in the means was then determined by testing a variety of gene abundances $\mu_g \in [10^{-3}, 10^3]$.
We repeated this procedure across 10 simulation iterations and reported the average of the maximum differences across iterations.
This was performed for each simulation scenario defined by the combination of the size factor for two groups ($a_1$ and $a_2$, where $a_1 \ge a_2$) and $\varphi$.

\subsection{Log-fold changes in the 10X ERCC data set}
We obtained the ERCC data set from the 10X Genomics website (\url{https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/ercc}).
We retained all libraries with total counts greater than 100.
Size factors were defined as the library sizes, scaled to a mean of unity across libraries.
We defined two groups in this data set, with the first group containing the top 20\% of libraries with the largest size factors and the second group containing the bottom 20\%.
For each ERCC transcript, we computed the log-normalized expression values using a pseudo-count of 1.
We then computed the differences in the mean log-values between groups to obtain an estimate of $\Delta_{12g}$.
For comparison, we also computed the log-fold change (i.e., $\delta_{12g}$) between groups based on the mean normalized expression.
Note that log-fold changes were computed after adding a pseudo-count of 1 to the means of both groups.

\subsection{Simulations with artifical structures}
Counts for 1000 genes in 500 cells were sampled independently from a Poisson distribution with a mean of $s_i$ for each cell $i$. 
The size factor $s_i$ for each cell was set to 0.1 for half of the cells and to 10 for the other half.
We computed log-normalized expression values for all cells with a pseudo-count of 1, as previously described.
We then performed PCA and examined the distribution of cells along the first two PCs.
We also repeated this simulation where $s_i$ was sampled from a Uniform$(0.1, 5)$ distribution instead.
Note that all genes are non-DE here, i.e., $E(X_{ig}/s_i)=1$ for all $g$ and $i$.

\bibliography{ref}
\bibliographystyle{unsrt}

\end{document}
