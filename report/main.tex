\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in,marginparwidth=2in]{geometry}

% use Unicode characters - try changing the option if you run into troubles with special characters (e.g. umlauts)
\usepackage[utf8]{inputenc}

% clean citations
\usepackage{cite}

% hyperref makes references clicky. use \url{www.example.com} or \href{www.example.com}{description} to add a clicky url
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% improves typesetting in LaTeX
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% text layout - change as needed
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Remove % for double line spacing
\usepackage{setspace} 
\doublespacing

% use adjustwidth environment to exceed text width (see examples in text)
\usepackage{changepage}

% adjust caption style
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,singlelinecheck=off]{caption}

% remove brackets from references
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% headrule, footrule and page numbers
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}

% use \textcolor{color}{text} for colored text (e.g. highlight to-do areas)
\usepackage{color}

% define custom colors (this one is for figure captions)
\definecolor{Gray}{gray}{.25}

% this is required to include graphics
\usepackage{graphicx}

% use if you want to put caption to the side of the figure - see example in text
\usepackage{sidecap}

% use for have text wrap around figures
\usepackage{wrapfig}
\usepackage[pscoord]{eso-pic}
\usepackage[fulladjust]{marginnote}
\reversemarginpar

% Adding multirow.
\usepackage{multirow}

% Other required things:
\usepackage{color}
\usepackage{subcaption}
\captionsetup[subfigure]{justification=centering}
\usepackage{amsmath}
\newcommand\code[1]{{\small\texttt{#1}}}

% document begins here
\begin{document}
\vspace*{0.35in}

% title goes here:
\begin{flushleft}
{\Large
    \textbf\newline{Using an appropriate pseudo-count for log-transformation of normalized single-cell RNA sequencing data}
}
\newline

% authors go here:
%\\
Aaron Lun\textsuperscript{1,*}
\\
\bigskip
\bf{1} Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\
\bigskip

\end{flushleft}

\section{Background}
Log-transformed expression values are widely used in analyses of single-cell RNA sequencing (scRNA-seq) and other transcriptomic data.
This is driven by the simplicity of the log-transformation and its variance stabilizing behaviour on many types of non-negative data.
In particular, the log-transformation reduces the impact of stochastic fluctuations in the counts for high-abundance genes.
This would otherwise result in large differences in the counts that are mostly uninteresting as the fold changes are small.
Differences between log-values are also approximately interpretable as log-fold changes between cells, which are often more relevant than differences in the counts.
This is useful for ensuring that relative rather than absolute differences in the counts are used in distance-based procedures like clustering or trajectory construction.

Despite its popularity, the log-transformation has a number of problems such as incomplete variance stabilization and arbitrariness in the choice of pseudo-count.
One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count \cite{hicks2017missing}.
This is problematic in (sc)RNA-seq contexts where the log-transformation is applied to normalized expression data.
Here, normalization is performed to remove inter-sample biases on the count scale \cite{robinson2010scaling,lun2016pooling}.
For genes that are not differentially expressed (DE), the expectation of the normalized expression is the same between samples.
However, the expectation of the log-normalized values may not be the same, resulting in spurious differences between samples/cells on the log-scale.

In this report, we describe the nature and impact of the discrepancy between log-mean and mean-log values.
We also show how the added pseudo-count can be increased to cap the discrepancy at the cost of reducing interpretability.

\section{Quantifying the discrepancy}
Let $X_{ig}$ denote a random variable for a non-negative count of a gene $g$ in cell $i$.
The size factor $s_i$ represents the scaling bias in $i$, which is removed by computing the normalized expression value $X_{ig}/s_i$ \cite{anders2010differential}.
The log-transformed normalized expression is defined as 
\[
Z_{ig} = \log\left(\frac{X_{ig}}{s_i}+ c\right) \;,
\]
where $c$ is a positive ``pseudo-count'' that ensures that the transformation is defined for $X_{ig} \ge 0$ and $s_i > 0$.
This calculation and its variants are widespread in analyses of count data from high-throughput sequencing experiments -- for example, a similar approach is used by the \code{cpm} function in the \textit{edgeR} package \cite{robinson2010edgeR}, differing only in a slight adjustment to the effective library size (equivalent to $s_i$) for a given prior count (equivalent to $c$).
The second-order Taylor series approximation for the expectation of $Z_{ig}$ is
\[
E(Z_{ig}) \approx \log[E(X_{ig}/s_i) + c] - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2[E(X_{ig}/s_i) + c]^2} \;.
\]
This expectation represents the mean of the log-normalized expression, while the first term on the right represents the log-mean normalized expression (after adding $c$). 
The second term on the right represents the discrepancy between these two values.

Now, consider two cells $i=1$ and $i=2$ that differ in their $s_i$.
Assume that $g$ is non-DE between these two cells such that $E(X_{ig}/s_i)=\mu_g$ for both.
The true log-fold change in the normalized expression values between these two cells is
\[
\delta_{12g} = \log\left[ \frac{E(X_{1g}/s_1)}{E(X_{2g}/s_2)} \right] = 0 \;.
\]
In analyses based on the log-transformed values, we use the expected difference in $Z_{ig}$ as a proxy for $\delta_{12g}$.
First, we simplify the expression for $E(Z_{ig})$ to
\[
E(Z_{ig}) \approx \log(\mu_g + c) - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2(\mu_g + c)^2} \;.
\]
This means that the difference in $E(Z_{ig})$ between these two cells is 
\begin{equation}
\Delta_{12g} \approx \frac{\mbox{var}(X_{1g})s_1^{-2} -  \mbox{var}(X_{2g})s_2^{-2}}{2(\mu_g + c)^2} \;. \label{eqn:spuriousdiff}
\end{equation}
In general, $\Delta_{12g} \neq 0$ due to differences in the size factors and subsequently variances (driven by the strong mean-variance relationship in count data).
This represents a spurious difference on the log-scale as the gene is not actually DE, i.e., $\delta_{12g}=0$.

We performed simulations to quantify this spurious difference in a range of scenarios for the typical $c=1$ (Figure~\ref{fig:maxeffect}).
We observed that it was most prominent when the size factors were different and either or both of them were less than unity.
This is consistent with Equation~\ref{eqn:spuriousdiff}, where $\Delta_{12g}$ increases in magnitude with smaller $s_i$.
We note that a 10-fold difference in the size factors across cells is not unusual in real scRNA-seq data \cite{lun2016pooling} due to the variability of capture efficiency and amplification.
In this situation, we can easily obtain a difference of 1 in the mean log$_2$-values between cells.
This corresponds to an artificial 2-fold change in expression that does not correspond to any biological effect.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the mean log$_2$-expression values for a non-DE gene due to size factor differences.
We simulated counts for non-DE genes in two groups of cells, where the size factor was the same for all cells in the same group (see Methods).
Each simulation scenario was defined by the size factor used for the first group ($a_1$), that for the second group ($a_2$), and the negative binomial dispersion.
For each scenario, we computed the difference between the mean $Z_{ig}$ for each group and determined the maximum difference across genes of varying abundance.
Values represent the average of the maximum across 10 simulation iterations.
Standard errors were negligible and are not shown.
For simplicity, we only show results for scenarios where $a_1 \ge a_2$.
}
\label{fig:maxeffect}
\end{figure}

We verified the existence of this effect in real scRNA-seq data from the 10X Genomics platform \cite{zheng2017massively}.
We used the publicly available ERCC data set (see Methods) in which gel emulsion beads containing ERCC spike-in transcripts were captured into droplets.
The composition of the ERCC transcripts should be constant in all droplets, so there should not be any difference in the expression profiles after library size normalization.
However, we observed a systematic non-zero difference in the mean log-expression values when comparing the smallest and largest droplets (Figure~\ref{fig:ercc}a).
This is fully attributable to the log-transformation, as no such difference is present in the log-fold change between the mean normalized expression values (Figure~\ref{fig:ercc}b).
Discrepancies between the difference in mean log-values and the log-fold change are also present in real scRNA-seq data sets with variable size factors (Figures~\ref{fig:ercc}c, d).

\begin{figure}
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../scripts/pics/real_brain.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../scripts/pics/real_pbmc.pdf}
    \caption{}
\end{subfigure}
\caption{Effect of the log-transformation on comparisons between groups in real scRNA-seq data.
(a) Differences in the mean $Z_{ig}$ between the top 20\% of libraries with the largest size factors and the bottom 20\% in the ERCC 10X Genomics data set (see Methods).
Each point represents a single ERCC spike-in transcript.
(b) Log-fold change in the mean normalized expression between the same groups of libraries for each ERCC transcript.
(c) Differences in the mean $Z_{ig}$ for two clusters of cells with the largest and smallest median size factors in a brain scRNA-seq data set \cite{zeisel2015brain},
compared to the log-fold change computed from the mean normalized expression.
Each point represents a gene.
(d) Same as (c) for the peripheral blood mononuclear cell (PBMC) data set \cite{zheng2017massively}.
}

\label{fig:ercc}
\end{figure}

The effect of spurious differences in $E(Z_{ig})$ is amplified in procedures that compute distances between cells.
Consider the Euclidean distance between the expected log-normalized expression profiles of our two cells $i=1$ and 2.
Ideally, the distance would be zero as there should be no difference in the expected location of these cells after normalization.
However, the actual distance will be approximately equal to the square root of the sum of $\Delta_{12g}^2$ across all (non-DE) genes used in the calculation.
This means that the distance between cells with different $s_i$ will be systematically larger than between cells with the same $s_i$.
As a result, spurious clusters or trajectories can form (Figure~\ref{fig:structures}) solely due to the log-transformation.
Such artificial structures can be highly misleading when characterizing the heterogeneity of a cellular population.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/clusters.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/trajectory.pdf}
    \caption{}
\end{subfigure}
\caption{Artificial structures induced by log-transformation in simulations with no true structure.
(a) Principal components analysis (PCA) plot of log-normalized expression values for non-DE genes in simulated cells with either very small or very large size factors (see Methods).
Each point represents a cell coloured according to its value of $s_i$.
The percentage of variance explained by each principal component (PC) is also shown in parentheses. 
(b) PCA plot for simulated cells with $s_i$ sampled from a continuous distribution.
Each point represents a cell coloured by its value of $s_i$.
}
\label{fig:structures}
\end{figure}

The discrepancy described in Equation~\ref{eqn:spuriousdiff} is also consistent with the observations from Hicks \emph{et al.} \cite{hicks2017missing}.
In their study, Hicks \emph{et al.} show that the log-normalized expression of many genes is anticorrelated with the ``detection rate'' (i.e. the percentage of non-zero counts in each cell) in a variety of scRNA-seq data sets.
We note that the detection rate is often strongly associated with the size factor due to the sparsity of the data.
Any increases to the coverage of a cell (and thus the size factor $s_i$) will naturally increase the detection rate as fewer zeroes are sampled,
such that both are correlated with any error induced by the log-transformation.
However, some caution is required when interpreting these correlations in real data due to the conflation of technical effects with genuine biological factors such as, e.g., differences in RNA content across cell types \cite{islam2011characterization,lun2017assessing}.

We wondered whether this problem of artificial differences could be mitigated by using alternative transformations.
We considered the square root, which provides variance stabilization for Poisson-distributed counts;
and the variance stabilizing transformation (VST) for negative binomial-distributed counts from \emph{DESeq2} \cite{love2014moderated}.
In simulations involving two groups of cells differing only in their size factors, we observed large differences in the group-specific means for non-DE genes after applying each transformation (Figure~\ref{fig:alttransform}).
This mirrors the mean-dependent nature of $\Delta_{12g}$ and indicates that variance stabilization does not inherently protect against spurious differences.
In fact, no transformation can truly stabilize the variance at low counts, which must increase from zero at a mean of zero.
This is problematic as many scRNA-seq data sets are dominated by low counts -- 81\% and 89\% of non-zero counts are below 5 in the brain and PBMC data sets, respectively --
which suggests that favouring alternative transformations on the basis of variance stabilization is largely misguided.

\begin{figure}
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
   \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
   \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\caption{Difference in the group-specific mean transformed expression values against the mean count for each gene, 
for Poisson-distributed counts (a, b, c) or NB-distributed counts (d, e, f) after applying a variety of transformations (see Methods).
Simulated count data was generated for non-DE genes in each of two groups of cells differing only in their size factors (smaller or larger).
Colour intensity is proportional to the density of genes, with outliers shown as points.
The red line represents a fitted loess curve.
}
\label{fig:alttransform}
\end{figure}

\section{Validating structure with DE analyses}
In our opinion, the most effect of greatest concern is the formation of spurious clusters and trajectories.
This can easily result in incorrect biological conclusions from an exploratory analysis of scRNA-seq data.
Fortunately, careful further analysis can provide some protection against these artificial structures.
Say that we identify spurious clusters like those in Figure~\ref{fig:structures}.
We attempt to characterize these clusters by identifying genes that are differentially expressed between them.
Here, the key is to use count-based models like edgeR \cite{robinson2010edgeR} to perform the DE analysis.
This directly accounts for complex mean-variance relationships in the count data, thereby avoiding the need for any transformation and concomitant artefacts.
If the analysis fails to yield any DE genes, we can infer that the separation was driven by the log-transformation and should be ignored.
This strategy is motivated by differences in the observed effect sizes depending on whether they are computed from transformed or untransformed data (Figure~\ref{fig:ercc}), possibly leading to different biological conclusions.
Our results indicate that untransformed data is more appropriate for these comparisons between groups.

While count-based models provide some protection from spurious structure, it is often the case that we still need to use per-gene transformed values for other steps in the analysis.
This includes visualization of expression between groups (e.g., in boxplots, or by colouring dimensionality reduction plots), for which the log-transformation is often used to preserve relative differences across a wide range of expression values.
It may also be more convenient to perform DE analyses on the log-transformed values, e.g., using $t$-tests \cite{law2014voom,soneson2018bias}, which are faster and simpler to implement than count-based models.
Thus, we would like to reduce $\Delta_{12g}$ as much as possible for these applications.
The most obvious method of doing so is to increase the pseudo-count.
Indeed, we could force $\Delta_{12g}$ to zero for all genes by setting $c$ to some arbitrarily large value.
However, as $c \to \infty$, the log-transformation approaches a linear transformation, i.e.,
\[
    Z_{ig} \approx \log(c) + \frac{X_{ig}}{s_i c} \;.
\]
Thus, using an arbitrarily large pseudo-count defeats the intended purpose of the log-transformation. 
No variance stabilization is achieved and differences in the transformed values cannot be used as proxies for log-fold changes. 
Instead, we aim to choose a pseudo-count that restricts $\Delta_{12g}$ to an ``acceptable'' level for each gene.

\section{Choosing a larger pseudo-count}
We assume that $X_{ig}$ follows a negative binomial (NB) distribution with mean $s_i\mu_g$ and dispersion $\varphi$.
This means that we can simplify the expression for $\Delta_{12g}$ to
\begin{align}
\Delta_{12g} 
&\approx \frac{\mu_g s_1^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} - \frac{\mu_g s_2^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} \nonumber \\
&= \frac{\mu_g (s_1^{-1} - s_2^{-1})}{2(\mu_g + c)^2} \;. \label{eqn:nberr}
\end{align}
This reaches its maximum absolute value for positive $\mu_g$ when $\mu_g = c > 0$, yielding 
\[
\tilde\Delta_{12g} = \left|\frac{(s_1^{-1} - s_2^{-1})}{8c}\right| \;.
\]
We can control the maximum error $\tilde\Delta_{12g}$ below a threshold $\tau$ by setting  
\[
    c = \rho |s_1^{-1} - s_2^{-1}| \;,
\]
where $\tau = (\rho 8)^{-1}$.
If we set $\rho = 1$, the maximum difference in the mean log-values should be 0.125 (or $[8\log(2)]^{-1} \approx 0.18$, on the $\log_2$-scale).
The observed maximum difference in simulations lies close to this bound at low dispersions (Figure~\ref{fig:cappederr}).
At higher dispersions, the bound becomes less accurate but is nonetheless still conservative.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the log-expression values for non-DE genes between groups of cells differing only in their size factors, 
after using an increased pseudo-count of $|s_1^{-1} - s_2^{-1}|$ prior to log-transformation.
Simulations and calculations were performed as described for Figure~\ref{fig:maxeffect}.
Results are only shown for scenarios where $s_1 > s_2$.
The red dashed line represents the theoretical bound on the maximum difference.
}
\label{fig:cappederr}
\end{figure}

In practice, downstream procedures such as clustering will compare many cells to one another instead of just two specific (groups of) cells.
Consequently, the exact choices of $s_1$ and $s_2$ are not obvious when calculating a single pseudo-count for the entire data set.
A general strategy is to set $s_1$ to the smallest size factor and $s_2$ to the largest size factor
(or robust equivalents thereof, e.g., the 5\textsuperscript{th} and 95\textsuperscript{th} percentiles).
This ensures that the difference in log-values for a non-DE gene does not exceed the theoretical upper bound for any pair of cells.
We thus define our empirical pseudo-count as
\[
\hat c = \max\{1, \rho |s_{min}^{-1} - s_{max}^{-1}|\} \;,
\]
which ensures that the pseudo-count is at least unity when all size factors are equal.
We suggest setting $\rho=1$, which provides a compromise between restricting $\tilde\Delta_{12g}$ and keeping the pseudo-count as small as possible.
Applying this strategy to the ERCC data set limits the maximum error close to the theoretical upper bound (Figure~\ref{fig:bigreal}a).

\begin{figure}
\begin{center}
    \includegraphics[width=0.5\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/ercc.pdf}
\end{center}
\caption{Effect of log-transformation with $\hat c$ and $\rho =1$ in the ERCC data set.
Differences in the mean $Z_{ig}$ are shown between the top and bottom 20\% of libraries with the largest and smallest size factors.
The red line denotes the theoretical limit on $\tilde \Delta_{12g}$.}
\label{fig:bigreal}
\end{figure}

We computed $\hat c$ for a number of real scRNA-seq data sets to examine its behaviour in practical settings. 
With $\rho=1$, we obtained $\hat c$ values of 1.36 for the 416B data set \cite{lun2017assessing}, 4.05 for the mouse brain data set \cite{zeisel2015brain} and 2.22 for the PBMC data set \cite{zheng2017massively}.
These values are within the typical range of pseudo-counts used for exploratory analyses of RNA-seq data \cite{chen2016reads}.
They also lie within the range of mean abundances in each data set -- we observed 217, 649 and 12636 genes with mean normalized expression values greater than $\hat c$ in the PBMC, brain and 416B data sets, respectively.
This indicates that the computed $\hat c$ is not so large as to entirely negate the variance stabilization from log-transformation.
It also justifies our strategy of controlling the maximum spurious difference $\tilde \Delta_{12g}$, which occurs when the mean normalized expression is close to $\hat c$.
(Otherwise, if all genes had lower abundances than $\hat c$, the maximum difference would never be achieved and our procedure would be unnecessarily conservative.)

% In theory, we could be less conservative by using gene-specific pseudo-counts.
% These would be computed by setting $\mu_g$ to the mean normalized expression of each gene, providing a more accurate measure of $\Delta_{12g}$ than the maximum across all $\mu_g$.
% This would allow smaller pseudo-counts to be used if $\Delta_{12g}$ was already low for a particular gene.
% However, for genes that are DE in a subset of cells, the mean count will not be a good proxy for the expected normalized expression in each cell.
% Consider a gene that is highly expressed in one cell type and lowly expressed in (and non-DE between) two other types.
% The large mean normalized expression for this gene drives the estimated $\Delta_{12g}$ to zero (Equation~\ref{eqn:nberr}), suggesting that a small pseudo-count can be used.
% This provides no protection against potentially large spurious differences between the other two cell types where the expected expression is low.
% For this reason (and simplicity), we use a single pseudo-count for the entire data set.

\section{Practical use of larger pseudo-counts}
Our suggestion is to use log-expression values computed with $\hat c$ during characterisation of population structures identified from exploratory analyses.
This avoids misleading differences upon visualizing expression values, as previously discussed.
For DE analyses, methods like TREAT \cite{mccarthy2009testing} can be applied to test whether the observed log-difference is significantly greater than the theoretical limit $\tau$.
This provides a statistically rigorous approach to DE testing when count-based models are impractical.
It is also possible to use log-values computed with $\hat c$ in the initial exploratory analysis, which may reduce the risk of detecting the spurious structures in the first place.
However, this strategy is more difficult to justify as the magnitude of the error in the distance between cells does not have a straightforward interpretion.
Any benefit from a large pseudo-count requires that the reduction in error is greater than the shrinkage of genuine biological differences.

Pseudo-counts are often set to unity for a number of reasons that have little to do with avoiding spurious differences.
One reason is to ensure that zero counts always yield zero log-values, which ensures that sparse matrix representations are still effective for reducing memory usage when analyzing large data sets.
A related motivation is to ensure that the log-transformed values are always non-negative, which is necessary for procedures such as non-negative matrix factorization.
However, there is no need to conflate these considerations with the choice of pseudo-count.
Some arithmetic yields 
\[
 \log\left(\frac{X_{ig}}{s_i}+ c\right) = \log\left(\frac{X_{ig}}{cs_i}+ 1\right) + \log c \;,
\]
where the constant $\log(c)$ on the right hand side can be ignored in any step that involves computing differences between log-values.
By computing the first term on the right, we can preserve sparsity and non-negativeness in the log-expression matrix.

As an aside, it is also worth commenting on the widespread use of log-transformed counts-per-million (CPM) values and their relatives, e.g., transcripts-per-million or fragments-per-kilobase-million.
Log-CPM values are typically computed by adding 1 to the CPM values, for the same reasons mentioned above.
However, this is equivalent to using a pseudo-count equal to the library size (i.e., total count across all genes) in millions.
For example, data sets with an average library size of 10 million would use a pseudo-count of 10, while data sets with an average library size of 10,000 would use a pseudo-count of 0.01.
This is not desirable as data sets with small library sizes are those with the largest $\Delta_{12g}$ (as $\mu_g$ is small) and in most need of large pseudo-counts.
In contrast, the approximation of the log-fold change by differences in log-values should improve with greater coverage.
Increasing the pseudo-count counteracts this effect such that the log-fold change estimates are not consistent with respect to coverage.

\section{Discussion}
It is worth speculating on some real situations in which the log-transformation is most likely to cause distortions.
Artifacts are most pronounced when the counts are low and there is large variation in the size factors across cells.
Both of these are often observed in data from droplet-based scRNA-seq protocols, as sequencing coverage is shared across a large number of libraries and reaction conditions are not precisely controlled for each droplet.
We would also expect the size factors within each experiment to vary across a continuum, yielding artificial trajectories (Figure~\ref{fig:structures}b) rather than distinct clusters (Figure~\ref{fig:structures}a).
This suggests that caution is required when interpreting trajectories that are correlated with the size factors, especially in low-coverage droplet-based data.

The ideal solution would be to use methods that model the counts directly to account for the mean-variance relationship.
For example, we could use \textit{BASiCS} \cite{vallejos2016beyond} for detecting highly variable genes or \textit{zinbwave} \cite{risso2018general} for factor analysis.
This would avoid the need for any variance-stabilizing transformation and subsequent distortion of the expected expression.
However, most existing methods for scRNA-seq data analysis (e.g., clustering, dimensionality reduction) do not use count-based models.
This is due to the difficulties in estimating model parameters, often separately for each gene and/or each cell,
compared to algorithms that only need distances between cells as input.
Thus, it is still desirable to obtain transformed data for compatibility with existing methods.

In the context of scRNA-seq analysis workflows, additional procedures can be used to reduce transformation-induced artifacts.
For example, quality control is typically performed to remove cells with small library sizes \cite{ilicic2016classification,lun2016stepbystep}.
This reduces the variation in the size factors and the potential for artificial differences upon log-transformation.
In addition, low-abundance genes can be filtered out, which provides further protection as genes with low counts are most affected by the log-transformation.
We note that the use of a larger pseudo-count will also reduce the influence of low-abundance genes.
This is a more nuanced approach than filtering, as it ensures that strong biological signal in low-abundance genes is not completely discarded for downstream applications.

% Another possible solution is to remove discrepancies empirically after transformation.
% This is done in various types of batch correction \cite{ritchie2015limma,haghverdi2018batch} where systematic differences in transformed values between batches are eliminated.
% It is, however, not straightforward to achieve in general as the magnitude of the discrepancy depends on the mean (Equation~\ref{eqn:spuriousdiff}).
% An empirical correction would require an approach similar to that used in \textit{SCnorm} \cite{bacher2017scnorm}.
% If we assume that most genes at any given abundance interval are mostly non-DE across all cells, any systematic trends in the transformed values with respect to $s_i$ for the genes in that interval must be artificial and should be removed.
% This assumption is considerably stronger than that used in scaling normalization (which only requires a non-DE majority across all genes),
% and cannot handle enrichment of DE genes, e.g., at high abundances due to strong upregulation.
% It is also difficult to fit an accurate and robust trend to discrete transformed values for low-abundance genes.
% 
% A more drastic approach would be to downsample all cells to match the cell with the smallest size factor.
% This would ensure that the variance (for Poisson-distributed counts) is the same across all cells, thus avoiding spurious log-fold changes between cells.
% However, it involves discarding a large amount of sequencing information and is equivalent to forcibly increasing the noise for high-quality cells that were deeply sequenced.
% Biological signal may subsequently be lost, especially if the size factors are highly variable and considerable downsampling is required.
% Downsampling also assumes that the counts are Poisson-distributed.
% This may be true for the sequencing itself \cite{marioni2008rnaseq} but is not true in general for library preparation.
% Overdispersion (e.g., due to PCR amplification) would mean that the downsampled counts of cells with large size factors will still have smaller variance than the counts of cells with small size factors.

Data transformations are powerful tools for exploratory analyses of scRNA-seq data.
However, they also have the potential to introduce artificial differences, as we have shown for the log-transformation.
Our recommendation is to increase the pseudo-count in cases where size factor variation may be responsible for spurious structure in the data.

\section{Methods}

\subsection{Simulated log-fold changes for non-DE genes}
We considered two groups of 10,000 cells where all cells in the same group $j$ were assigned the same size factor $s_i=a_j$.
For a non-DE gene $g$, the count $X_{ig}$ for each cell $i$ was independently sampled from a negative binomial distribution with mean $s_i\mu_g$ and dispersion $\varphi$.
We computed $Z_{ig}$ for all cells in each group using a pseudo-count $c$ of 1 as previously described.
The difference in the mean $Z_{ig}$ between groups represents an estimate of $\Delta_{12g}$.
The maximum difference in the means was then determined by testing a variety of gene abundances $\mu_g \in [10^{-3}, 10^3]$.
We repeated this procedure across 10 simulation iterations and reported the average of the maximum differences across iterations.
This was performed for each simulation scenario defined by the combination of the size factor for two groups ($a_1$ and $a_2$, where $a_1 \ge a_2$) and $\varphi$.

\subsection{Log-fold changes in real data sets}
We obtained the ERCC data set from the 10X Genomics website (\url{https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/ercc}).
We retained all libraries with total counts greater than 100.
Size factors were defined as the library sizes, scaled to a mean of unity across libraries.
We defined two groups in this data set, with the first group containing the top 20\% of libraries with the largest size factors and the second group containing the bottom 20\%.
For each ERCC transcript, we computed the log-normalized expression values using a pseudo-count of 1.
We then computed the differences in the mean log-values between groups to obtain an estimate of $\Delta_{12g}$.
For comparison, we also computed the log-fold change (i.e., $\delta_{12g}$) between groups based on the mean normalized expression.
Note that log-fold changes were computed after adding a pseudo-count of 1 to the means of both groups.

For the 416B, brain and PBMC data sets, counts were processed according to a published workflow \cite{lun2016stepbystep}.
Briefly, low-quality cells were removed with the \emph{scater} package \cite{mccarthy2017scater} and size factors were computed using the deconvolution method \cite{lun2016pooling}.
PCA was performed on the log-normalized expression values (computed with a pseudo-count of 1) after modelling the mean-variance trend, 
and cells were clustered based on their PC scores using the shared nearest neighbours method \cite{xu2015identification}.
In each data set, we identified the two clusters with the largest and smallest median size factors.
We computed the difference in the mean log-expression values between clusters and compared this to the log-fold change between clusters calculated from the mean normalized expression.
Note that kog-fold changes were calculated after adding a pseudo-count of 1 to the means of both groups,
such that any discrepancy between the difference in mean log-values and the log-fold change is an estimate of $\Delta_{12g}$.

\subsection{Simulations with artifical structures}
Counts for 1000 genes in 500 cells were sampled independently from a Poisson distribution with a mean of $\lambda_i$ for each cell $i$. 
We set $\lambda_i=0.1$ for half of the cells and $\lambda_i=10$ for the other half.
The size factor for each cell was defined as $\lambda_i$ after being scaled to a mean of unity across cells.
We computed log-normalized expression values for all cells with a pseudo-count of 1, as previously described.
We then performed PCA and examined the distribution of cells along the first two PCs.
We also repeated this simulation where $b_i$ was sampled from a Uniform$(0.1, 5)$ distribution instead.
Note that all genes are non-DE in these simulations, i.e., $E(X_{ig}/s_i)$ is constant for all $g$ and $i$.

\subsection{Simulations with different transformations}
Counts for 10,000 genes in 500 cells were sampled from a Poisson or negative binomial distribution with the mean of $\lambda_i \mu_g$ for each cell $i$.
We sampled $\log_2(\mu_g)$ from a Uniform$(-5, 10)$ distribution to obtain a range of gene abundances.
We partitioned the cells into two groups of equal size, setting $\lambda_i=0.1$ for all cells in one group and $\lambda_i=10$ for all cells in the other group.
For the negative binomial distribution, we used a constant dispersion of 1 for simplicity.
The size factor for cell $i$ was defined as $\lambda_i$ after being scaled to a mean of unity across cells.
We applied the tested transformations -- square root, log, and VST -- to the normalized expression values, using a pseudo-count of 1 for the log$_2$-transformation and \code{fitType="mean"} for the \textit{DESeq2} VST.
We then computed the mean of the transformed values in each group for each gene.

\bibliography{ref}
\bibliographystyle{unsrt}

\end{document}
