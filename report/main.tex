\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in,marginparwidth=2in]{geometry}

% use Unicode characters - try changing the option if you run into troubles with special characters (e.g. umlauts)
\usepackage[utf8]{inputenc}

% clean citations
\usepackage{cite}

% hyperref makes references clicky. use \url{www.example.com} or \href{www.example.com}{description} to add a clicky url
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% improves typesetting in LaTeX
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% text layout - change as needed
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Remove % for double line spacing
%\usepackage{setspace} 
%\doublespacing

% use adjustwidth environment to exceed text width (see examples in text)
\usepackage{changepage}

% adjust caption style
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,singlelinecheck=off]{caption}

% remove brackets from references
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% headrule, footrule and page numbers
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}

% use \textcolor{color}{text} for colored text (e.g. highlight to-do areas)
\usepackage{color}

% define custom colors (this one is for figure captions)
\definecolor{Gray}{gray}{.25}

% this is required to include graphics
\usepackage{graphicx}

% use if you want to put caption to the side of the figure - see example in text
\usepackage{sidecap}

% use for have text wrap around figures
\usepackage{wrapfig}
\usepackage[pscoord]{eso-pic}
\usepackage[fulladjust]{marginnote}
\reversemarginpar

% Adding multirow.
\usepackage{multirow}

% Other required things:
\usepackage{color}
\usepackage{subcaption}
\captionsetup[subfigure]{justification=centering}
\usepackage{amsmath}
\newcommand\code[1]{{\small\texttt{#1}}}

% document begins here
\begin{document}
\vspace*{0.35in}

% title goes here:
\begin{flushleft}
{\Large
    \textbf\newline{Using an appropriate pseudo-count for log-transformation of normalized single-cell RNA sequencing data}
}
\newline

% authors go here:
%\\
Aaron Lun\textsuperscript{1,*}
\\
\bigskip
\bf{1} Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\
\bigskip

\end{flushleft}

\section{Background}
Log-transformed expression values are widely used in analyses of single-cell RNA sequencing (scRNA-seq) and other transcriptomic data.
This is driven by the simplicity of the log-transformation and its variance stabilizing behaviour on many types of non-negative data.
In particular, the log-transformation reduces the impact of stochastic fluctuations in the counts for high-abundance genes.
This would otherwise result in large differences in the counts that are mostly uninteresting as the fold changes are small.
Differences between log-values are also approximately interpretable as log-fold changes between cells, which are often more relevant than differences in the counts.
This is useful for ensuring that the relative rather than absolute differences in the counts are used in distance-based procedures like clustering or trajectory construction.

Despite its popularity, the log-transformation has a number of problems such as incomplete variance stabilization and arbitrariness in the choice of pseudo-count.
One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count \cite{hicks2017missing}.
This is problematic in (sc)RNA-seq contexts where the log-transformation is applied to normalized expression data.
Here, normalization is performed to remove inter-sample biases on the count scale \cite{robinson2010scaling,lun2016pooling}.
For genes that are not differentially expressed (DE), the expectation of the normalized expression is the same between samples.
However, the expectation of the log-normalized values may not be the same, resulting in spurious differences between samples/cells on the log-scale.

In this report, we describe the nature and impact of the discrepancy between log-mean and mean-log values.
We also show how the added pseudo-count can be increased to cap the discrepancy at the cost of reducing interpretability.

\section{Quantifying the discrepancy}
Let $X_{ig}$ denote a random variable for a non-negative count of a gene $g$ in cell $i$.
The size factor $s_i$ represents the scaling bias in $i$, which is removed by computing the normalized expression value $X_{ig}/s_i$.
The log-transformed normalized expression is defined as 
\[
Z_{ig} = \log(X_{ig} / s_i + c) \;,
\]
where $c$ is a pseudo-count that ensures that the transformation is defined for $X_{ig} \ge 0$.
The second-order Taylor series approximation for the expectation of $Z_{ig}$ is
\[
E(Z_{ig}) \approx \log[E(X_{ig}/s_i) + c] - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2[E(X_{ig}/s_i) + c]^2} \;.
\]
The second term represents the discrepancy between the mean-log and the log-mean.

Now, consider two cells $i=1$ and $i=2$ that differ in their $s_i$.
Assume that $g$ is non-DE between these two cells such that $E(X_{ig}/s_i)=\mu_g$ for both.
The true log-fold change in the normalized expression values between these two cells is
\[
\delta_{12g} = \log\left[ \frac{E(X_{1g}/s_1)}{E(X_{2g}/s_2)} \right] = 0 \;.
\]
In analyses based on the log-transformed values, we use the difference in $E(Z_{ig})$ as a proxy for $\delta_{12g}$.
First, we simplify the expression for $E(Z_i)$ to
\[
E(Z_{ig}) \approx \log(\mu_g + c) - \frac{\mbox{var}(X_{ig})s_i^{-2}}{2(\mu_g + c)^2} \;.
\]
This means that the difference in $E(Z_{ig})$ between these two cells is 
\begin{equation}
\Delta_{12g} \approx \frac{\mbox{var}(X_{1g})s_1^{-2} -  \mbox{var}(X_{2g})s_2^{-2}}{2(\mu + c)^2} \;. \label{eqn:spuriousdiff}
\end{equation}
In general, $\Delta_{12g} \neq 0$ due to differences in the size factors and subsequently variances (driven by the strong mean-variance relationship in count data).
This represents a spurious difference on the log-scale as the gene is not actually DE, i.e., $\delta_{12g}=0$.

We performed simulations to quantify this spurious difference in a range of scenarios for the typical $c=1$ (Figure~\ref{fig:maxeffect}).
We observed that it was most prominent when the size factors were different and either or both of them were less than unity.
This is consistent with Equation~\ref{eqn:spuriousdiff}, where $\Delta_{12g}$ increases in magnitude with smaller $s_i$.
We note that a 10-fold difference in the size factors across cells is not unusual in real scRNA-seq data \cite{lun2016pooling} due to the variability of capture efficiency and amplification.
However, even in this situation, we can obtain a difference of 1 in the mean log-values.
This corresponds to an artificial 2-fold change in expression that does not correspond to any biological effect.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/max_effect.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the log-expression values for non-DE simulated data.
Each difference was computed between the average $Z_{ig}$ of 10000 counts for $i=1$ and 2 with $c=1$.
Counts were sampled from a negative binomial distribution with mean $\mu_g s_i$ and the specified dispersion $\varphi$.
For each combination of the first size factor ($s_1$), second size factor ($s_2$) and $\varphi$, the maximum difference was determined across all $\mu_g \in [10^{-3}, 10^3]$.
Maximum differences are only shown for scenarios where $s_1 \ge s_2$, for simplicity.
}
\label{fig:maxeffect}
\end{figure}

The effect of these spurious differences is amplified in distance calculations involving hundreds or thousands of affected genes.
The value of $\Delta_{12g}$ is effectively summed across many non-DE genes, resulting in a systematic increase in the distance between cells with different $s_i$. 
This results in the formation of spurious clusters or trajectories (Figure~\ref{fig:structures}) based solely on the log-transformation.
Such artificial structures can be highly misleading when characterizing the heterogeneity of a cellular population.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/clusters.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/trajectory.pdf}
    \caption{}
\end{subfigure}
\caption{Artificial structures induced by the log-transformation in simulations with no true structure.
(a) Principal components analysis (PCA) plot of $Z_{ig}$ computed with $c=1$, for cells with large ($s_i =10$) and small size factors ($s_i=0.1$), 
Counts for 1000 genes in 500 cells were sampled independently from a Poisson distribution with a mean of $s_i$ for each cell $i$. 
Each point represents a cell, coloured by whether its $s_i$ was large or small.
The percentage of variance explained by each principal component (PC) is also shown in parentheses. 
(a) PCA plot of $Z_{ig}$ computed with $c=1$, for cells with $s_i$ sampled from an exponential distribution with rate of 1.
Counts were sampled as described for (a).
Each point represents a cell coloured according to the value of $s_i$.
}
\label{fig:structures}
\end{figure}

We verified the existence of this effect in real scRNA-seq data from the 10X Genomics platform \cite{zheng2017massively}.
We used the publicly available ERCC data set (\url{https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/ercc}) in which gel emulsion beads containing ERCC spike-in transcripts were captured into droplets.
The composition of the ERCC transcripts should be constant in all droplets, so there should not be any difference in the expression profiles after library size normalization.
However, we observed a systematic non-zero difference in the mean log-expression values when comparing the smallest and largest droplets (Figure~\ref{fig:ercc}a).
This is fully attributable to the log-transformation, as no such difference is present in the log-fold change between the mean normalized expression values (Figure~\ref{fig:ercc}b).

\begin{figure}
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/ercc.pdf}
    \caption{}
\end{subfigure}
\caption{Effect of log-transformation on the comparison between large and small droplets in the ERCC 10X Genomics data set.
(a) Differences in the mean $Z_{ig}$ between the top 20\% of libraries with the largest size factors and the bottom 20\%.
Size factors were calculated by scaling the library sizes to a mean of unity across cells.
The pseudo-count was set to unity.
Only libraries with total counts above 100 were considered.
Each point represents a single ERCC spike-in transcript.
(b) Log-fold change in the mean normalized count between the same groups of libraries for each ERCC transcript.}
\label{fig:ercc}
\end{figure}

\section{Exploring possible remedies}
The obvious solution is to not perform any transformation and to model the counts directly in all analyses.
For example, methods like \textit{edgeR} \cite{robinson2010edgeR} can be used for DE analyses;
methods like \textit{BASiCS} \cite{vallejos2016beyond} for detecting differentially or highly variable genes;
and methods like \textit{zinbwave} \cite{risso2018general} for factor analysis.
This accounts for the mean-variance relationship while avoiding any distortion of the expected expression.
However, most existing methods for scRNA-seq data analysis (e.g., clustering, dimensionality reduction) do not use count-based models.
This is attributable to the difficulties in estimating model parameters, often separately for each gene and/or each cell,
compared to algorithms that only need distances between cells as input.
Thus, it is still desirable to obtain transformed data for compatibility with existing analysis methods.

Another possible solution is to remove discrepancies empirically after transformation.
This is done in various types of batch correction \cite{ritchie2015limma,haghverdi2018batch} where systematic differences in transformed values between batches are eliminated.
It is, however, not straightforward to achieve in general as the magnitude of the discrepancy depends on the mean (Equation~\ref{eqn:spuriousdiff}).
An empirical correction would require an approach similar to that used in \textit{SCnorm} \cite{bacher2017scnorm}.
If we assume that most genes at any given abundance interval are mostly non-DE across all cells, any systematic trends in the transformed values with respect to $s_i$ for the genes in that interval must be artificial and should be removed.
This assumption is considerably stronger than that used in scaling normalization (which only requires a non-DE majority across all genes),
and cannot handle enrichment of DE genes, e.g., at high abundances due to strong upregulation.
It is also difficult to fit an accurate and robust trend to discrete transformed values for low-abundance genes.

A more drastic approach would be to downsample all cells to match the cell with the smallest size factor.
This would ensure that the variance (for Poisson-distributed counts) is the same across all cells, thus avoiding spurious log-fold changes between cells.
However, it involves discarding a large amount of sequencing information and is equivalent to forcibly increasing the noise for high-quality cells that were deeply sequenced.
Biological signal may subsequently be lost, especially if the size factors are highly variable and considerable downsampling is required.
Downsampling also assumes that the counts are Poisson-distributed.
This may be true for the sequencing itself \cite{marioni2008rnaseq} but is not true in general for library preparation.
Overdispersion (e.g., due to PCR amplification) would mean that the downsampled counts of cells with large size factors will still have smaller variance than the counts of cells with small size factors.

Finally, we explore the use of other transformations with different statistical properties.
We considered the square root, which provides good variance stabilization for Poisson-distributed counts;
and the variance stabilizing transformation (VST) for negative binomial (NB)-distributed counts from \emph{DESeq2} \cite{love2014moderated}.
In simulations of non-DE genes, we observed large differences in the mean of transformed values with both transformations (Figure~\ref{fig:alttransform}).
This indicates that variance stabilization does not protect against spurious differences in the mean.
Perhaps no single transformation exists that 
(i) yields transformed values that are easily interpretable,
(ii) provides complete variance stabilization, and
(iii) avoids spurious differences in the mean of transformed values.

\begin{figure}
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_pois.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/alternative_nb.pdf}
    \caption{}
\end{subfigure}
\caption{Distribution of mean expression values for Poisson-distributed counts (a, b, c) or NB-distributed counts (d, e, f) after applying a variety of transformations.
Simulated count data was generated for 10000 genes in 500 cells, with the mean count set to 1 for half of the cells (smaller group) and 100 for the other half (larger group).
The dispersion was set to 1 for the NB simulations.
Size factors were calculated by scaling the library sizes to a mean of unity across cells.
Transformations were applied to the size factor-scaled counts, using a pseudo-count of 1 for the log$_2$-transformation and \code{fitType="mean"} for the \textit{DESeq2} VST.
Boxplots represent the distribution of mean transformed values across genes, with outlier genes shown as separate dots.
}
\label{fig:alttransform}
\end{figure}

\section{Choosing a larger pseudo-count}
In theory, we could minimize $\tilde\Delta_{12g}$ by setting $c$ to some arbitrarily large value.
However, as $c \to \infty$, the log-transformation approaches a linear transformation, i.e.,
\[
    Z_{ig} \approx \log(c) + \frac{X_{ig}}{s_i c} \;.
\]
Thus, using an arbitrarily large pseudo-count defeats the intended purpose of the log-transformation. 
No variance stabilization is achieved and differences in the transformed values cannot be used as proxies for log-fold changes. 
Instead, our aim must be to choose the smallest pseudo-count that restricts $\tilde\Delta_{12g}$ to an ``acceptable'' level.

We assume that $X_{ig}$ follows a negative binomial (NB) distribution with mean $s_i\mu_g$ and dispersion $\varphi$.
This means that we can simplify the expression for $\Delta_{12g}$ to
\begin{align*}
\Delta_{12} 
&\approx \frac{\mu_g s_1^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} - \frac{\mu_g s_2^{-1} + \varphi \mu_g^2}{2(\mu_g + c)^2} \\ 
&= \frac{\mu_g (s_1^{-1} - s_2^{-1})}{2(\mu_g + c)^2} \;.
\end{align*}
This spurious difference in the log-expression values is maximized when $\mu_g = c$, yielding 
\[
\tilde\Delta_{12g} = \frac{(s_1^{-1} - s_2^{-1})}{8c} \;.
\]
Thus, we can cap the maximum error $\tilde\Delta_{12g}$ regardless of the values of $s_i$ by requiring 
\[
    c \propto |s_1^{-1} - s_2^{-1}| \;.
\]
If we set the proportionality constant $\rho$ to unity, the maximum log-difference should be 0.125 (or $[8\log(2)]^{-1} \approx 0.18$, on the $\log_2$-scale).
We observe this bound in a range of simulation scenarios (Figure~\ref{fig:cappederr}), indicating that our approximation is accurate.

\begin{figure}[btp]
\centering
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=1]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=2]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=4]{../scripts/pics/error_bound.pdf}
    \caption{}
\end{subfigure}
\caption{Maximum difference in the log-expression values for non-DE simulated data after setting $c$ to $|s_1^{-1} - s_2^{-1}|$.
Each difference was computed between the average $Z_{ig}$ of 10000 counts for $i=1$ and 2.
Counts were sampled from a negative binomial distribution with mean $\mu_g s_i$ and the specified dispersion $\varphi$.
For each combination of the first size factor ($s_1$), second size factor ($s_2$) and $\varphi$, the maximum difference was determined across all $\mu_g \in [10^{-3}, 10^3]$.
Results are not shown for scenarios where $s_1=s_2$ as no difference in log-expression is expected (dashed lines connect adjacent points for ease of visualization).
}
\label{fig:cappederr}
\end{figure}

In practice, downstream procedures such as clustering will compare many cells to one another instead of just two specific (groups of) cells.
The exact choices of $s_1$ and $s_2$ are not obvious when considering the calculation of a single pseudo-count for the entire data set.
A general strategy is to set $s_1$ to the smallest size factor and $s_2$ to the largest size factor
(or robust equivalents thereof, e.g., the 5\textsuperscript{th} and 95\textsuperscript{th} percentiles).
This ensures that the difference in log-values for a non-DE gene does not exceed the theoretical upper bound for any pair of cells.
We thus define our empirical pseudo-count as
\[
\hat c = \max\{1, \rho |s_{min}^{-1} - s_{max}^{-1}|\} \;,
\]
which ensures that the pseudo-count is at least unity when all size factors are equal.
We suggest setting $\rho=1$, which provides a compromise between restricting $\tilde\Delta_{12g}$ and keeping the pseudo-count as small as possible.
Applying this strategy to the ERCC data set limits the maximum error close to the theoretical upper bound (Figure~\ref{fig:bigreal}a).

\begin{figure}
\begin{center}
    \includegraphics[width=0.5\textwidth,trim=0mm 5mm 0mm 5mm,clip,page=3]{../scripts/pics/ercc.pdf}
\end{center}
\caption{Effect of log-transformation with $\hat c$ and $\rho =1$ in the ERCC data set.
Differences in the mean $Z_{ig}$ are shown between the top and bottom 20\% of libraries with the largest and smallest size factors.
The red line denotes the theoretical limit on $\tilde \Delta_{12g}$.}
\label{fig:bigreal}
\end{figure}

To explore the behaviour of $\hat c$ in real data, we computed $\hat c$ for a number of real scRNA-seq data sets from the \href{http://bioconductor.org/packages/devel/workflows/html/simpleSingleCell.html}{\emph{simpleSingleCell}} workflows.
Here, low-quality cells were removed with the \emph{scater} package \cite{mccarthy2017scater} and size factors were computed using the deconvolution method \cite{lun2016pooling}.
With $\rho=1$, we obtained $\hat c$ values of 1.36 for the 416B data set \cite{lun2017assessing}, 4.05 for the mouse brain data set \cite{zeisel2015brain} and 2.22 for the peripheral bone mononuclear cell (PBMC) data set \cite{zheng2017massively}.
These values are typical of pseudo-counts used for exploratory analyses of RNA-seq data \cite{chen2016reads}.
They are also lower than the largest average counts per gene for each data set (PBMC: 216, brain: 1664, 416B: 63215),
indicating that our recommended value for the pseudo-count is not so large as to entirely negate the variance stabilization activity of the log-transformation.     

\section{Consequences of increasing the pseudo-count}
The strength of our definition of $\hat c$ is that it can adaptively increase according to the observed variation in the size factors.
However, this is not without consequences.
A larger pseudo-count will mitigate the effect of spurious differences in non-DE genes but will also compromise interpretation of log-fold changes for genuine DE genes.
A near-zero difference between subpopulations for low-abundance genes cannot be treated as an accurate estimate of the true log-fold change. 
This is obviously problematic if important changes in expression of low-abundance genes are overlooked due to the small magnitude of the difference in log-values.
Greater shrinkage also means that distance calculations are driven by moderate- to high-abundance genes.
This will prevent the resolution of biological signal that is only present in low-abundance genes.

%That said, detection power for DE genes in a formal hypothesis testing framework is mostly unaffected (Figure~\ref{fig:power}).
%This is because the larger $c$ also reduces the variance in the log-transformed values, 
%thus compensating for the decrease in the mean difference.

%\begin{figure}
%\begin{center}
%\includegraphics[width=\textwidth]{../scripts/pics/power.pdf}
%\end{center}
%\caption{Welch $t$-statistics as a function of the DE fold change, for log-transformed data with a variety of added pseudo-counts.
%We considered an experimental design with 1000 cells in each group.
%Counts were sampled from a NB distribution with a mean of $\mu$ in one group and $f\mu$ in the other group for some fold change $f$.
%Log$_2$-transformed values were computed with a range of pseudo-counts, and a Welch $t$-statistic was computed for the difference in transformed values between groups.
%All size factors were set to unity during the transformation, to reflect the fact that $f$ represents geniune DE. 
%}
%\label{fig:power}
%\end{figure}

We recommend the following strategy to mitigate the disadvantages of using a larger pseudo-count.
Initial exploratory analyses should be performed with the default pseudo-count, e.g., $c=1$.
This avoids excessive shrinkage of biological differences for low-abundance genes, especially if such shrinkage is unnecessary, 
e.g., size factors do not differ systematically between clusters or across trajectories.
However, if there is a correlation between the putative structures and size factors, the analysis should be repeated with a larger pseudo-count of $\hat c$. 
(For comparisons between specific subpopulations, it is possible to choose the pseudo-count more carefully based on differences in their $s_i$.
We will use the most general approach here for simplicity.)
This ensures that any differential expression is not driven by the log-transformation.

It is also worth stressing that the use of $\hat c$ only caps the spurious difference on a per-gene basis.
Small gene-wise errors can add up to a large systematic error in the distance between cells, introducing artificial structures like those in Figure~\ref{fig:structures}.
For example, consider two cells from the same population that differ only in their $s_i$.
Further consider the Euclidean distance between the expectation of the log-expression vectors for these cells.
The maximum distance in the log-space is $(8\rho)^{-1}\sqrt{n}$, where $n$ is the number of (in this case, non-DE) genes.
Unlike the log-fold change, it is difficult to determine an intuitive ``acceptable'' limit for the spurious distance.
Controlling it below a fixed value would also require $\rho \propto \sqrt{n}$, resulting in a prohibitively large $\hat c$.

While artificial increases in the distance are obviously undesirable, they should be considered in the context of the entire exploratory analysis for scRNA-seq data.
Say that, even after using $\hat c$, we still identify spurious clusters like those in Figure~\ref{fig:structures}.
We attempt to characterize these clusters by identifying genes that are differentially expressed between them.
At this point, the per-gene upper bound guaranteed by $\hat c$ becomes relevant as it limits the size of the spurious log-fold changes.
It is then simple for the analyst to disregard genes with small log-fold changes below $\tilde \Delta_{12g}$,
either by manual inspection or by using the upper bound in methods such as TREAT \cite{mccarthy2009testing}.
If no relevant DE genes remain after this pruning, we ignore the spurious separation between these clusters.
In this manner, the use of $\hat c$ protects us from misleading conclusions.

\section{Discussion}
It is worth speculating on some real situations in which the log-transformation is most likely to cause distortions.
Artifacts are most pronounced when the counts are low and there is large variation in the size factors across cells.
Both of these are often observed in data from droplet-based scRNA-seq protocols, as sequencing coverage is shared across a large number of libraries and reaction conditions are not precisely controlled for each droplet.
We would also expect the size factors within each experiment to vary across a continuum, yielding artificial trajectories (Figure~\ref{fig:structures}b) rather than distinct clusters (Figure~\ref{fig:structures}a).
This suggests that caution is required when interpreting trajectories that are correlated with the size factors, especially in low-coverage droplet-based data.

In the context of scRNA-seq analysis workflows, additional procedures can be used to reduce transformation-induced artifacts.
For example, quality control is typically performed to remove cells with small library sizes \cite{ilicic2016classification,lun2016stepbystep}.
This reduces the variation in the size factors and the potential for artificial differences upon log-transformation.
In addition, low-abundance genes can be filtered out, which provides further protection as genes with low counts are most affected by the log-transformation.
We note that the use of a larger pseudo-count will also reduce the influence of low-abundance genes.
This is a more nuanced approach than filtering, as it ensures that strong biological signal in low-abundance genes is not completely discarded for downstream applications.

Data transformations are powerful tools for exploratory analyses of scRNA-seq data.
However, they also have the potential to introduce artificial differences, as we have shown for the log-transformation.
Our recommendation is to increase the pseudo-count in cases where size factor variation may be responsible for spurious structure in the data.

\bibliography{ref}
\bibliographystyle{unsrt}

\end{document}
